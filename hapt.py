# -*- coding: utf-8 -*-
"""HAPT.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1eGnoPGtwpbx0S2ZCJzwxiR5YtsLuz8dp

# Human Activity Recognition and Postural Transitions dataset

## Data reading
"""

import zipfile
path_to_zip_file = "HAPT_Data_Set.zip"
directory_to_extract_to = "HAPT"

with zipfile.ZipFile(path_to_zip_file, 'r') as zip_ref:
    zip_ref.extractall(directory_to_extract_to)

import pandas as pd
import seaborn as sns
import numpy as np
from matplotlib import pyplot as plt
from sklearn.decomposition import PCA 
from matplotlib import pyplot
from imblearn.over_sampling import SMOTE,BorderlineSMOTE, ADASYN, KMeansSMOTE, SVMSMOTE
from sklearn import svm
from sklearn.metrics import f1_score, accuracy_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_val_score
import timeit, time

feature_names = pd.read_csv("HAPT/features.txt", header = None).values.reshape(561)
activity_labels = pd.read_csv("HAPT/activity_labels.txt", header = None).values

# train and test have been collected from different subjects activity, iid samples hypotesis. 70/30 ratio
X_train = pd.read_csv("HAPT/Train/X_train.txt", sep= " ", header = None)
y_train = pd.read_csv("HAPT/Train/y_train.txt", sep= " ", header = None, names = ["label"])

X_test = pd.read_csv("HAPT/Test/X_test.txt", sep= " ", header = None)
y_test = pd.read_csv("HAPT/Test/y_test.txt", sep= " ", header = None, names = ["label"])

X_train

X_train.shape, y_train.shape, y_test.shape, X_test.shape

feature_names[:15], activity_labels

"""## Data cleaning"""

# search for NaN 
X_train.isnull().values.any() # return false if NO Null values have been found

"""## Data exploration

### Analysis on the distribution of the target class and validation of the test train split provided
"""

X_train_label = X_train.copy(deep=False)
X_train_label["label"] = y_train.values

# class distribution in the training set 
fig, ax = pyplot.subplots(figsize=(15,7))
graph = sns.countplot(data = y_train, x = "label", palette="viridis")
graph.axes.set_title("Istances in the training set per class value",fontsize=25)
graph.set_xlabel("Label",fontsize=20)
graph.set_ylabel("Number of istances",fontsize=20)
sns.set_style("whitegrid")
graph.tick_params(labelsize = 15)
fig.savefig('dist_training.png', dpi=300)

# class distribution in the test set
fig, ax = pyplot.subplots(figsize=(15,7))
graph = sns.countplot(data = y_test, x = "label", palette="viridis")
graph.axes.set_title("Istances in the test set per class value",fontsize=25)
graph.set_xlabel("Label",fontsize=20)
graph.set_ylabel("Number of istances",fontsize=20)
sns.set_style("whitegrid")
graph.tick_params(labelsize = 15)
fig.savefig('dist_test.png', dpi=300)

"""### Data exploration on signle features"""

# select the feature you want to see the distribution
feature_number = 555 #50, 68, 389, 555 , 25, 120
print('The feature selected is: ', feature_names[feature_number])

# plot of the distribution
plt.figure(figsize=(60,55))
sns.displot(X_train_label, x=feature_number, hue="label", kind="kde", height=5, aspect=15/4, palette = "viridis") #50
plt.xlabel("Value", fontsize = 20)
plt.ylabel("Density", fontsize = 20)
plt.title("Probability distribution per class value of the feature: {}".format(feature_names[feature_number]), fontsize = 25)
plt.savefig('{}.png'.format(feature_number))

"""## Data Augmentation

### Oversampling
"""

# We can choose among different sets of oversampling methods
start = time.time()

# sm = BorderlineSMOTE(random_state=42)
sm = KMeansSMOTE(random_state=42, cluster_balance_threshold = 0.05)
# sm = SVMSMOTE(random_state=42)
# sm = ADASYN(random_state=42)

X_res, y_res = sm.fit_resample(X_train.values, y_train.values)

print(time.time() - start)

y_res = y_res.astype(int)
X_train_res = pd.DataFrame(np.append(X_res, y_res.reshape(len(y_res),1), axis = 1))
X_train_res.rename(columns = {561:'label'}, inplace = True)
X_train_res = X_train_res.astype({'label':'int'})

# generate the table used to plot time of execution
x = ['ADASYN', 'borderline SMOTE', 'SVM SMOTE', 'KMeans SMOTE']
y = np.array([[2.9436838626861572, 2.8723678588867188 , 39.373571157455444, 5.778373956680298]])
temp = pd.DataFrame(y, columns = x)
temp

# time: [bsmote, svmsmote, kmeanssmote] [ 2.8723678588867188 , 39.373571157455444, 5.778373956680298]
plt.figure(figsize=(10,7))
graph = sns.barplot(data = temp , palette = "viridis") 
plt.xlabel("Oversampling technique", fontsize = 20)
plt.ylabel("time [s]", fontsize = 20)
plt.title("Computation time required per oversampling technique" , fontsize = 22)
graph.tick_params(labelsize = 15)
plt.savefig('time.png')

# select the feature you want to see the distribution
feature_number = 120 #50, 68, 120
print('The feature selected is: ', feature_names[feature_number])

# plot of the distribution
plt.figure(figsize=(60,55))
sns.displot(X_train_res, x=feature_number, hue='label', kind="kde", height=5, aspect=15/4, palette = "viridis") 
plt.xlabel("Value", fontsize = 20)
plt.ylabel("Density", fontsize = 20)
plt.title("Probability distribution per class value of the feature: {}".format(feature_names[feature_number]), fontsize = 25)
plt.savefig('{}_res.png'.format(feature_number))

# class distribution after oversampling
fig, ax = pyplot.subplots(figsize=(15,7))
graph = sns.countplot(data = X_train_res, x = 'label', palette="viridis")
graph.axes.set_title("Istances in the training set after oversampling",fontsize=25)
graph.set_xlabel("Label",fontsize=20)
graph.set_ylabel("Number of istances",fontsize=20)
sns.set_style("whitegrid")
graph.tick_params(labelsize = 15)
fig.savefig('dist_training_over.png', dpi=300)

"""### PCA"""

pca = PCA(n_components = 50)

# PCA module fitting of out set
pca.fit(X_res)
X_res_pca = pca.transform(X_res)
X_test_pca = pca.transform(X_test)

# Computation of three variables that will be used to generate graphs
# Array of percentace of explained variance by component  
percentage_variance = np.array(pca.explained_variance_ratio_)

# Array of variance explained by component
variances = np.array(pca.explained_variance_)

# Array of cumulative explained variance by component 
cum_variances = []
for i in range(len(percentage_variance)):
    cum_variances.append(sum(percentage_variance[0:i+1]))

#Graph rapresenting the cumulative percentage of explained variance
# The graphs in the can be replicated using n_components = 50

fig, ax = pyplot.subplots(figsize=(20,7))
graph = sns.barplot(ax = ax, y = cum_variances, x = np.arange(1,51,1), palette = "viridis")
graph.axhline(0.8, color = 'red')
graph.axes.set_title("Cum. % of expl. variance",fontsize=25)
graph.set_xlabel("Principal component",fontsize=20)
graph.set_ylabel("% of expl. variance",fontsize=20)
sns.set_style("whitegrid")
graph.tick_params(labelsize = 15)

#The plot is shown
plt.show()
fig.savefig('cum.png', dpi=300)

#Graph rapresenting the percentage of explained variance by component

fig, ax = pyplot.subplots(figsize=(20,7))
graph = sns.barplot(ax = ax, y = percentage_variance, x = np.arange(1,51,1), palette = "viridis")
graph.axhline(0.04, color = 'red')
graph.axes.set_title("% of expl. variance by component",fontsize=25)
graph.set_xlabel("Principal component",fontsize=20)
graph.set_ylabel("% of expl. variance",fontsize=20)
sns.set_style("whitegrid")
graph.tick_params(labelsize = 15)

#The plot is shown
fig.savefig('var.png', dpi=300)

# Scatter plot to visualize on the dataset in the principal component space

# The dataset in the space of the first two pricipal component

c = np.array(X_res_pca)

fig, ax = plt.subplots()
ax.set_facecolor('white')
plt.grid(color='grey', linestyle='solid')
fig.set_size_inches(10,7)
ax.scatter(X_res_pca[:,0], X_res_pca[:,1], c=y_res, cmap = 'viridis')

ax.set_xlabel(r'Principal component 1', fontsize=20)
ax.set_ylabel(r'Principal component 2', fontsize=20)
ax.set_title('Distribution of the Variables \nin the PC1-PC2 space',fontsize=30)

ax.grid(True)
fig.tight_layout()

plt.show()
fig.savefig('pc1pc2.png', dpi=300)

#scatter plot to visualize on the dataset in the principal component space

# The dataset in the space of the first two pricipal component

c = np.array(X_res_pca)

fig, ax = plt.subplots()
ax.set_facecolor('white')
plt.grid(color='grey', linestyle='solid')
fig.set_size_inches(10,7)
ax.scatter(X_res_pca[:,0], X_res_pca[:,2], c = y_res, cmap = 'viridis')

ax.set_xlabel(r'Principal component 1', fontsize=20)
ax.set_ylabel(r'Principal component 3', fontsize=20)
ax.set_title('Distribution of the Variables \nin the PC1-PC3 space',fontsize=30)
ax.legend()

ax.grid(True)
fig.tight_layout()

plt.show()
fig.savefig('pc1pc3.png', dpi=300)

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline

fig = plt.figure()
ax = fig.add_subplot(111, projection='3d')
ax.set_facecolor('xkcd:white')
plt.grid(color='w', linestyle='solid')
fig.set_size_inches(13,10)
ax.scatter(X_res_pca[:,0], X_res_pca[:,1], X_res_pca[:,2], c=y_res, cmap = "viridis")

ax.set_xlabel(r'Principal component 1', fontsize=17)
ax.set_ylabel(r'Principal component 2', fontsize=17)
ax.set_zlabel(r'Principal component 3', fontsize=17)
ax.set_title('Distribution of the Galaxies \nin the PC1-PC2-PC3 space',fontsize=25)

fig.tight_layout()

plt.show()
# fig.savefig('pc1pc2pc3.png', dpi=300)

"""## Model selection

### SVM
"""

# Hyperparameter search
# We perform cross validation changing the oversampling techniques and PCA component.
# for the full dataset change X_res_pca to X_res

clf = svm.SVC()
score = cross_val_score(clf, X_res_pca, y_res, cv=5, scoring= "f1_micro")
np.mean(score)

# After we choose the type of preprocessing we can compute the final accuracy on the test set
clf = svm.SVC()
clf.fit(X_res_pca, y_res)
y_pred = clf.predict(X_test_pca)
f1_score(y_test, y_pred, average = 'micro')

"""### Random forest"""

# Hyperparameter search
# We perform cross validation changing the oversampling techniques and PCA component.

clf = RandomForestClassifier(random_state=0)
score = cross_val_score(clf, X_res_pca, y_res_pca, cv=5, scoring= "f1_micro")
np.mean(score)

# After we choose the type of preprocessing we can compute the final accuracy on the test set
clf = RandomForestClassifier(random_state=0)
clf.fit(X_res_pca, y_res)
y_pred = clf.predict(X_test_pca)
f1_score(y_test, y_pred, average = 'micro')